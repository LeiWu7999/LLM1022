# 1022冲刺CCF-A

## 总事件进展
- 2024/11/15 第一次组会，梳理 LLM Reasoning 领域研究现状，划分研究方向
- 2025/4/20 回归科研，研究模型参数融合和隐空间推理
## Idea💡
*Can Language Models Learn to Skip Steps?*

<div align="center">
<img src="lzq\图片池\skip_step.png" alt="MHA/MQA/GQA/MLA">
</div>

> 可以尝试利用 $D_0$ 和 $D_i'$构建偏好数据对，对应 $ D_i' $ 里的答案，若存在正确且短的，就让模型偏好这个，若存在短的但是错误的就偏好原始长的且正确的


## 实验计划
- xxx
## Lzq阶段表
>2025/4 隐空间推理调研

>2025/4/23 阅读综述

>2025/4/24 阅读论文《Token Assorted: Mixing Latent and Text Tokens for Improved Language Model Reasoning》

## 外部资源链接
- [llm推理相关大集合] [Awesome-LLM-Strawberry](https://github.com/hijkzzz/Awesome-LLM-Strawberry/)
- [LlamaFactory] [LLaMA-Factory QuickStart](https://zhuanlan.zhihu.com/p/695287607)
- [国内下Huggingface模型的方法] [如何快速下载huggingface模型](https://zhuanlan.zhihu.com/p/663712983)

